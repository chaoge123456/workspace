{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "log = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(latent, 32*7*7),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(32, 64, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(64, 128, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(128, 1, 3, stride=1, padding=1),\n",
    "            nn.Tanh() \n",
    "        )\n",
    "    def forward(self, x):\n",
    "        out = self.fc(x).view(x.shape[0], 32, 7, 7)\n",
    "        out = self.conv(out)\n",
    "        return out\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        def block(in_ch, out_ch):\n",
    "            layer = [\n",
    "                nn.Conv2d(in_ch, out_ch, 3, stride=2),\n",
    "                nn.BatchNorm2d(out_ch),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "            ]\n",
    "            return layer\n",
    "        self.conv = nn.Sequential(\n",
    "            *block(1,16),\n",
    "            *block(16, 32),\n",
    "            *block(32, 64),\n",
    "        )\n",
    "        self.fc = nn.Sequential(nn.Linear(64*2*2, 1), nn.Sigmoid())\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x).view(x.shape[0], -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torchvision.datasets.MNIST(root='../dataset/', download=True, train=True, transform=torchvision.transforms.ToTensor())\n",
    "train_iter = torch.utils.data.DataLoader(train_data, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent = 64\n",
    "lr = 0.001\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Generator(latent)\n",
    "D = Discriminator()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer_G = torch.optim.RMSprop(G.parameters(), lr=lr)\n",
    "optimizer_D = torch.optim.RMSprop(D.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0, Loss_D:1.2923063069581986, Loss_G:0.8715248972177505\n",
      "Epoch:0, Loss_D:1.2252220833301544, Loss_G:0.8858872091770172\n",
      "Epoch:0, Loss_D:1.1880201625823974, Loss_G:0.9403862822055816\n",
      "Epoch:0, Loss_D:1.1503397953510284, Loss_G:1.000281991958618\n",
      "Epoch:1, Loss_D:1.0974978071451187, Loss_G:1.0759896692633628\n",
      "Epoch:1, Loss_D:1.0539874160289764, Loss_G:1.1371852385997772\n",
      "Epoch:1, Loss_D:1.0329025620222092, Loss_G:1.180043706893921\n",
      "Epoch:1, Loss_D:0.9943048256635666, Loss_G:1.231670112013817\n",
      "Epoch:2, Loss_D:0.9700254577398301, Loss_G:1.3036437118053437\n",
      "Epoch:2, Loss_D:0.9333375543355942, Loss_G:1.365861603617668\n",
      "Epoch:2, Loss_D:0.9324185431003571, Loss_G:1.390927066206932\n",
      "Epoch:2, Loss_D:0.9266565871238709, Loss_G:1.4229617846012115\n",
      "Epoch:3, Loss_D:0.8929119223356247, Loss_G:1.4801906883716582\n",
      "Epoch:3, Loss_D:0.9017980432510376, Loss_G:1.4619097673892976\n",
      "Epoch:3, Loss_D:0.8991804713010788, Loss_G:1.4575238847732543\n",
      "Epoch:3, Loss_D:0.8909874248504639, Loss_G:1.5032166826725006\n",
      "Epoch:4, Loss_D:0.8724734473228455, Loss_G:1.5273460993170738\n",
      "Epoch:4, Loss_D:0.8527245581150055, Loss_G:1.5826389765739441\n",
      "Epoch:4, Loss_D:0.884641450047493, Loss_G:1.5134657913446425\n",
      "Epoch:4, Loss_D:0.865380688905716, Loss_G:1.5648660135269166\n",
      "Epoch:5, Loss_D:0.8318158489465713, Loss_G:1.5881687033176421\n",
      "Epoch:5, Loss_D:0.8650648158788681, Loss_G:1.5475112062692642\n",
      "Epoch:5, Loss_D:0.8831225955486297, Loss_G:1.5603087115287781\n",
      "Epoch:5, Loss_D:0.8568723058700561, Loss_G:1.5821155419945716\n",
      "Epoch:6, Loss_D:0.8067417633533478, Loss_G:1.6039992076158525\n",
      "Epoch:6, Loss_D:0.8359777218103409, Loss_G:1.6237474650144577\n",
      "Epoch:6, Loss_D:0.8404158645868302, Loss_G:1.6376799184083939\n",
      "Epoch:6, Loss_D:0.833059709072113, Loss_G:1.6419245028495788\n",
      "Epoch:7, Loss_D:0.8417463910579681, Loss_G:1.65359494805336\n",
      "Epoch:7, Loss_D:0.8136297291517258, Loss_G:1.6681631886959076\n",
      "Epoch:7, Loss_D:0.8295243430137634, Loss_G:1.6738305336236954\n",
      "Epoch:7, Loss_D:0.8261177599430084, Loss_G:1.6265839976072312\n",
      "Epoch:8, Loss_D:0.8017354536056519, Loss_G:1.65580495595932\n",
      "Epoch:8, Loss_D:0.809139010310173, Loss_G:1.6607020425796508\n",
      "Epoch:8, Loss_D:0.8371088874340057, Loss_G:1.7125418555736542\n",
      "Epoch:8, Loss_D:0.8551717764139175, Loss_G:1.6810469651222228\n",
      "Epoch:9, Loss_D:0.8236500084400177, Loss_G:1.7307975971698761\n",
      "Epoch:9, Loss_D:0.8153624022006989, Loss_G:1.6920731109380722\n",
      "Epoch:9, Loss_D:0.8273996430635452, Loss_G:1.7226537299156188\n",
      "Epoch:9, Loss_D:0.8434985065460205, Loss_G:1.6994100111722945\n",
      "Epoch:10, Loss_D:0.8039939379692078, Loss_G:1.7164878714084626\n",
      "Epoch:10, Loss_D:0.807623084783554, Loss_G:1.705788658261299\n",
      "Epoch:10, Loss_D:0.8354222863912583, Loss_G:1.687337911128998\n",
      "Epoch:10, Loss_D:0.8327760857343673, Loss_G:1.7120054656267165\n",
      "Epoch:11, Loss_D:0.7915356063842773, Loss_G:1.687744140625\n",
      "Epoch:11, Loss_D:0.8150753170251847, Loss_G:1.7674266469478608\n",
      "Epoch:11, Loss_D:0.8103318750858307, Loss_G:1.7573084861040116\n",
      "Epoch:11, Loss_D:0.8359275448322296, Loss_G:1.701561758518219\n",
      "Epoch:12, Loss_D:0.7751457780599594, Loss_G:1.7340365689992905\n",
      "Epoch:12, Loss_D:0.7914507508277893, Loss_G:1.7404153317213058\n",
      "Epoch:12, Loss_D:0.8089762890338897, Loss_G:1.703282997608185\n",
      "Epoch:12, Loss_D:0.8104033213853836, Loss_G:1.7720103612542153\n",
      "Epoch:13, Loss_D:0.8106634736061096, Loss_G:1.7896111226081848\n",
      "Epoch:13, Loss_D:0.7737947887182236, Loss_G:1.7669652384519576\n",
      "Epoch:13, Loss_D:0.8420784068107605, Loss_G:1.760505209863186\n",
      "Epoch:13, Loss_D:0.7890896582603455, Loss_G:1.7692136108875274\n",
      "Epoch:14, Loss_D:0.8184782981872558, Loss_G:1.820290032029152\n",
      "Epoch:14, Loss_D:0.7770179921388626, Loss_G:1.7634837234020233\n",
      "Epoch:14, Loss_D:0.8042452543973923, Loss_G:1.7845561450719833\n",
      "Epoch:14, Loss_D:0.7793343988060951, Loss_G:1.7963886362314225\n",
      "Epoch:15, Loss_D:0.7669565671682358, Loss_G:1.7762366765737534\n",
      "Epoch:15, Loss_D:0.8483731591701508, Loss_G:1.749749359190464\n",
      "Epoch:15, Loss_D:0.7818548649549484, Loss_G:1.8187194645404816\n",
      "Epoch:15, Loss_D:0.8053545075654983, Loss_G:1.7908573693037033\n",
      "Epoch:16, Loss_D:0.8114828908443451, Loss_G:1.7336760208010673\n",
      "Epoch:16, Loss_D:0.758814155459404, Loss_G:1.8222822523117066\n",
      "Epoch:16, Loss_D:0.7954148906469345, Loss_G:1.6967356294393539\n",
      "Epoch:16, Loss_D:0.7928204965591431, Loss_G:1.7957702189683915\n",
      "Epoch:17, Loss_D:0.7968218362331391, Loss_G:1.8076828956604003\n",
      "Epoch:17, Loss_D:0.7959151184558868, Loss_G:1.751095615029335\n",
      "Epoch:17, Loss_D:0.7838263809680939, Loss_G:1.79703011572361\n",
      "Epoch:17, Loss_D:0.7965164467692375, Loss_G:1.7918233650922775\n",
      "Epoch:18, Loss_D:0.7800448748469353, Loss_G:1.77041075527668\n",
      "Epoch:18, Loss_D:0.7751659941673279, Loss_G:1.8500726854801177\n",
      "Epoch:18, Loss_D:0.8104098296165466, Loss_G:1.7525399830937385\n",
      "Epoch:18, Loss_D:0.7973665255308151, Loss_G:1.7819447302818299\n",
      "Epoch:19, Loss_D:0.8089041864871979, Loss_G:1.813583461344242\n",
      "Epoch:19, Loss_D:0.7903332561254501, Loss_G:1.8536497139930725\n",
      "Epoch:19, Loss_D:0.8008727321028709, Loss_G:1.731062284708023\n",
      "Epoch:19, Loss_D:0.8352618199586869, Loss_G:1.7188416755199432\n"
     ]
    }
   ],
   "source": [
    "log = log + 1\n",
    "writer = SummaryWriter(log_dir='dcnn/'+str(log))\n",
    "num = 0\n",
    "test = torch.normal(0, 1, (32, latent))\n",
    "for epoch in range(epochs):\n",
    "    avg_loss_g = 0.0\n",
    "    avg_loss_d = 0.0\n",
    "    for i, (real_img, _) in enumerate(train_iter):\n",
    "        batch_size = real_img.shape[0]\n",
    "        \n",
    "        real_label = torch.ones(batch_size, 1)\n",
    "        fake_label = torch.zeros(batch_size, 1)\n",
    "        \n",
    "        # 训练判别器\n",
    "        d_real = D(real_img)\n",
    "        d_real_loss = criterion(d_real, real_label)\n",
    "        \n",
    "        z = torch.normal(0, 1, (batch_size, latent))\n",
    "        fake_img = G(z)\n",
    "        d_fake = D(fake_img)\n",
    "        d_fake_loss = criterion(d_fake, fake_label)\n",
    "        \n",
    "        optimizer_D.zero_grad()\n",
    "        d_loss = d_real_loss + d_fake_loss\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "        \n",
    "        # 训练生成器\n",
    "        z = torch.normal(0, 1, (batch_size, latent))\n",
    "        fake_img = G(z)\n",
    "        d_fake = D(fake_img)\n",
    "        g_loss = criterion(d_fake, real_label)\n",
    "        \n",
    "        optimizer_G.zero_grad()\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        avg_loss_g += g_loss.item()\n",
    "        avg_loss_d += d_loss.item()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print(\"Epoch:{}, Loss_D:{}, Loss_G:{}\".format(epoch, avg_loss_d/100, avg_loss_g/100))\n",
    "            writer.add_scalar('Loss_D', avg_loss_d/100, num)\n",
    "            writer.add_scalar('Loss_G', avg_loss_g/100, num)\n",
    "            avg_loss_g = 0.0\n",
    "            avg_loss_d = 0.0\n",
    "            num += 1\n",
    "    with torch.no_grad():\n",
    "        s = \"Epoch-\"+str(epoch)\n",
    "        show = torch.clamp(G(test), 0, 1)\n",
    "        writer.add_images(s, show, 0)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8f6a9a9880>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "G.eval()\n",
    "z = torch.normal(0, 1, (1, latent))\n",
    "image = G(z)\n",
    "img = torchvision.transforms.ToPILImage()(image.reshape(28,28))\n",
    "plt.imshow(img,cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
